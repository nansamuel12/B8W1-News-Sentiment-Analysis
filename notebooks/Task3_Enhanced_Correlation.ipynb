{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Enhanced Data Preparation & Correlation Analysis\n",
    "\n",
    "Complete workflow:\n",
    "1. Data Preparation & Date Normalization\n",
    "2. Sentiment Analysis\n",
    "3. Calculate Daily Stock Returns\n",
    "4. Aggregate Sentiments\n",
    "5. Pearson Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load & Normalize Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load news\n",
    "news_df = pd.read_csv('../data/raw_analyst_ratings.csv')\n",
    "news_df['date'] = pd.to_datetime(news_df['date'], utc=True).dt.tz_localize(None)\n",
    "news_df['trading_date'] = pd.to_datetime(news_df['date'].dt.date)\n",
    "\n",
    "# Load stocks\n",
    "tickers = ['AAPL', 'AMZN', 'GOOG', 'META', 'MSFT', 'NVDA']\n",
    "stock_data = {}\n",
    "for ticker in tickers:\n",
    "    df = pd.read_csv(f'../data/Data/{ticker}.csv')\n",
    "    df['trading_date'] = pd.to_datetime(df['Date'])\n",
    "    df = df.sort_values('trading_date')\n",
    "    stock_data[ticker] = df\n",
    "\n",
    "print(f\"News: {len(news_df)} records\")\n",
    "print(f\"Stocks loaded: {len(tickers)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader = SentimentIntensityAnalyzer()\n",
    "\n",
    "news_df['sentiment_textblob'] = news_df['headline'].apply(lambda x: TextBlob(str(x)).sentiment.polarity)\n",
    "news_df['sentiment_vader'] = news_df['headline'].apply(lambda x: vader.polarity_scores(str(x))['compound'])\n",
    "news_df['sentiment_score'] = (news_df['sentiment_textblob'] + news_df['sentiment_vader']) / 2\n",
    "\n",
    "print(\"Sentiment calculated\")\n",
    "news_df[['headline', 'sentiment_score']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Calculate Daily Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ticker in tickers:\n",
    "    stock_data[ticker]['Daily_Return'] = stock_data[ticker]['Close'].pct_change() * 100\n",
    "\n",
    "print(\"Daily returns calculated\")\n",
    "stock_data['AAPL'][['trading_date', 'Close', 'Daily_Return']].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Aggregate Daily Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_sentiment = news_df.groupby('trading_date').agg({\n",
    "    'sentiment_score': ['mean', 'std', 'count']\n",
    "}).reset_index()\n",
    "daily_sentiment.columns = ['trading_date', 'sentiment_mean', 'sentiment_std', 'news_count']\n",
    "\n",
    "print(f\"Aggregated: {len(daily_sentiment)} days\")\n",
    "daily_sentiment.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Merge & Calculate Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "merged_data = {}\n",
    "\n",
    "for ticker in tickers:\n",
    "    merged = pd.merge(\n",
    "        stock_data[ticker][['trading_date', 'Close', 'Daily_Return']],\n",
    "        daily_sentiment[['trading_date', 'sentiment_mean']],\n",
    "        on='trading_date'\n",
    "    ).dropna()\n",
    "    \n",
    "    corr, pval = stats.pearsonr(merged['sentiment_mean'], merged['Daily_Return'])\n",
    "    \n",
    "    results[ticker] = {'Correlation': corr, 'P_Value': pval, 'N': len(merged)}\n",
    "    merged_data[ticker] = merged\n",
    "    \n",
    "    print(f\"{ticker}: r={corr:.4f}, p={pval:.4f}, n={len(merged)}\")\n",
    "\n",
    "pd.DataFrame(results).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 2, figsize=(16, 15))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, ticker in enumerate(tickers):\n",
    "    df = merged_data[ticker]\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    ax.scatter(df['sentiment_mean'], df['Daily_Return'], alpha=0.5)\n",
    "    z = np.polyfit(df['sentiment_mean'], df['Daily_Return'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    ax.plot(df['sentiment_mean'], p(df['sentiment_mean']), \"r--\", linewidth=2)\n",
    "    \n",
    "    corr = results[ticker]['Correlation']\n",
    "    pval = results[ticker]['P_Value']\n",
    "    ax.set_title(f'{ticker}: r={corr:.3f}, p={pval:.4f}', fontweight='bold')\n",
    "    ax.set_xlabel('Sentiment Score')\n",
    "    ax.set_ylabel('Daily Return (%)')\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
